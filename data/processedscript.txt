yeah thanks for the invitation to speak so i tried to make this summoner a little bit i guess materials project themed so some of the questions are razor sort of inspired by um being a user um of the materials project for quite a while and i'm going to jump straight in and so for materials modeling i think the typical workflow is that we want to map between structure and properties so that's typically it we use different codes different approaches but we want to make that mapping and i think you can break it up into three parts so usually we have an input that's a crystal structure and often it's either directly from x-ray diffraction experiments or if it's it's inspired by diffraction experiments so you're taking the structure of a known material and maybe changing the composition or modifying the structure in a particular way of course one of the pioneers in in modern crystallography was kathleen lonsdale just pointing to her and then we have to make a choice in the hamiltonian so the interactions that we want to describe in the system and the interactions between electrons between ion and electrons for example and of course this follows hamiltonian mechanics that was developed by william hamilton and then we want to think about the properties of the system that we care about so it could be mechanical properties optical electronic and i think the job of a computational scientist is really to choose the hamiltonian that's appropriate for the system of interest for that chemistry for that structure type and also for the property that you care about and so you might make a particular choice if you care about magnetism and you could get away with sort of a model hamiltonian that describes exchange interactions between electrons and so you could predict for example magnetic susceptibility and but generally in first principles of materials modeling we want to have a hamiltonian that's as complete as possible so we want to describe as many of the interactions in our system that we can to make the predictions as general as possible and so that's a point i'll come back to a little bit later and but what i would say is that practically um we have to make choices so choices that are pragmatic that we can actually we have a hamiltonian that we can solve for our system in a reasonable time frame and sort of going back to this early quote from paul dirac so it follows he said at the time that chemistry was a solved problem so quantum mechanics had been developed in the early 20th century and because the schrodinger or direct equation can describe the electronic distribution of any combination of elements therefore chemistry was solved but the practical problem was the equations were too difficult to solve for any realistic system so this is a quote from one of his papers so approximate method should be developed which can lead to an explanation of the main features of complex atomic systems without too much computation and this really sums up the next century of effort and in theoretical and computational science so trying to reduce sort of the schrodinger direct equations which describe all of the physics and of the systems we care about into a form that's tractable and i think now typically we deal with sort of different sets of approximations so we have analytical expressions such as like leonard jones or buckingham and where we have a closed form that describes the interaction between elements so when the elements get too close you get the um you get um repulsion when the you have sort of a sweet spot for the equilibrium bond length and then you have sort of longer range van der waals interactions so that's sort of leonard jones type of course that's very straightforward to deal with computationally so now we can have classical force field simulations for systems of millions or billions of atoms so still very powerful techniques but maybe the majority of super computing time at least public super super computing time right now would be spent on numerical solutions um of for example the conscham equations so there we make particular approximations to make the equation solvable and for sort of systems that we care about so usually systems ranging i guess from a couple to hundreds or sometimes thousands of atoms and then more recently we have a whole new set of statistical approximations and so using machine learning we can also describe interactions between elements we can describe structure and composition property relationships and so this is really taking advantage of machine learning models as function approximators so if we don't know the exact function that relates the input structure to the output property perhaps we can and train a model that will a machine learning model that will describe it okay so that was paul dirac in the late 1920s if you move forward a few decades and at that particular time so this really the development of modern computing started and charles coulson wrote a very nice essay on a split in the field of theoretical chemistry so those theoretical chemists that were focused on having accurate analytical solutions of sort of quantum mechanical problems of several electrons interacting and there's a group of people working on sort of approximations to allow allow us to treat larger and more complex systems and but he worked out sort of the information that you need to encode to describe the interacting wave function of 20 electrons and figure out that surpassed and what would be possible in the foreseeable future so he made this prediction that around 20 electrons would be an upper limit to what would ever be possible to calculate and of course he couldn't really see what was what was coming in the future and and these days it's becoming possible to solve sort of control equations for systems of definitely hundreds or thousands of electrons so for example this methyl organic framework qio66 and if you're treating it in an all-electron simulation the unit cell has 752 electrons and but yet we can do it now for two reasons so one is that we have much larger computers so if you look at top 500 so the ranking of public supercomputers we now have many systems with over 1 million processors and which is quite incredible how quickly and the complexity of supercomputers has grown and including some nice ones in the us and but you also have to pay attention to the power usage so some of these like taking um sort of 29 000 kilowatts of power for the number one supercomputer that basically would require an old-fashioned coal power plant just to power that one supercomputer and in terms of the in terms of the capacity so it's definitely something that's playing on my mind in terms of how we can be as efficient as possible in our use of resource and i think databases such as the materials project is one way that we can reduce sort of the the need to keep re-running the same calculations over and over so definitely one side parallel computing is playing a big role in able to sort of brute force and solve these equations for larger systems and then of course we have the algorithms that are sort of powering uh powering them and a common bottleneck in in first principles modeling is simply matrix diagonalization so as a matrix gets larger and larger so as you have more basis functions it becomes much more difficult to distribute that task on many processors and but there has been a lot of work in in applied maths and computer science in making this more efficient so i use the code fha aims a lot that and and they've been involved in the development of this alpha library which has been been really impressive in the rate of progress that now so you can start to diagonalize a matrix that has more than of dimensions greater than 500 000 using sort of over 20 000 cores quite efficiently so 3d thanks to hardware and some of these software developments that we can start to go beyond treating very simple systems using dft start to treat things such as dislocations and grain boundaries that wouldn't have been possible and even five or ten years ago so that was a little bit of context and so i said this this seminar i want to make a little bit bespoke and and i've broken it up into at least past present and future as i see it in terms of materials modeling but sort of drawing i guess from my progression and over the years and so i started my phd about 20 years ago and i think a lot has changed since then and that was really when we were doing one compound at a time with dft so these calculations are very expensive we're using reasonable and super computing clusters to solve control equations for relatively simple systems and so my phd was focused on understanding so connections between chemistry crystal structure and physical properties and with a strong focus on post-transition metal compounds so looking at for example the differences between tin dioxide so sno2 versus is tin monoxide so sno so it changes large changes in the crystal structure in the band structure and in the semiconducting properties and towards the end of my phd we actually got a new supercomputer in dublin i actually can't remember the size right now and but enable it it enables us to do larger calculations than ever before so i was very excited to work on this system bismuth standards so this was the most complex inorganic crystal structure that had been solved from powder diffraction at the time so i think over 300 atoms in the unit cell and so we're able to solve the electronic structure and look at some of the sort of some of the interesting features associated with this bismuth lone pair so you can see this asymmetric electron density but at the time it seemed like very fundamental work sort of just looking at interactions between bismuth and oxygen and business and sulfur and it was just later in my career somehow these lone pairs kept coming back and so applications in terms of electrocatalysts and photocatalysts and solar cells and a range of materials these sort of lone pair states ended up re-emerging and primarily as a way to increase conductivity and increase absorption in the visible range of the electromagnetic spectrum so systems like bismuth-vanidate are being quite widely used as um photo catalysts for water splitting but that was my phd and but for my post-doctoral research i wanted to get a little bit more applied so i ended up moving to colorado and to work at the national renewable energy lab where my focus was on high throughput simulations so there i had access to much larger computers thanks to the us department of energy and we could think about running many dft calculations so orders of magnitude more than i was doing for my phd and at the time i was quite inspired by mineral structures and the idea of taking these sort of prototype structures for example here is the kesterite mineral that can be found in russia and thinking about substituting in alternative elements and looking at the possible chemical space that could be formed inside those mineral structures and and that was a really fun time and so kestrel actually forms a diamond based um super lattice so you have this sort of zinc blend diamond structure that you can populate with a single element it's diamond two elements it's a blend three element it's a caltraparite and four elements it's kesterite and then you can think about the possible chemical space that you can access by substituting in those elements and so of course there are a number of known compounds binary ternary quaternary but there's also a large number of unknown and that perhaps could be made so we spent a long time exploring and performing many such calculations and really cool things so within that single crystal space we identified potential and materials for solar cells and spin transport materials are very strong spin over coupling and also a family of topological insulators and so that was a really productive time using dft to be quite exploratory in terms of crystal space but what i would say so i was trained formally as a computational chemist and you can see i was getting quite deep into condensed matter physics so i had a chance i got a marie curie fellowship to move to the uk and sort of think about my research direction a little bit so i decided to combine my interest in chemistry and physics and devote some time to organic inorganic systems so paying attention to some emerging activity in the field of hybrid semiconductors so materials formed from inorganic and organic building blocks but yet they could still conduct charge so quite different to the sort of first wave of metal organic frameworks that were very much wide band gap and dielectric insulators so systems such as this that is um sort of a mixture of lead sulfide and these sort of aromatic rings and you give rise to very low effective masses and some quite high levels of conductivity and that ended up being quite a strong stream of research for me so trying to translate concepts from semiconductor physics so things like band engineering and to the field of hybrid solids or metal organic frameworks so in this particular case taking a quite a wide band gap and wider band gap but yet photoactive crystal and making serious substitutions on the ligands they tried to control and the band energies so that was a pretty fun time but what i would say sort of back then 10 years ago it was incredibly difficult to set up calculations for metal organic frameworks and so often the structures you get from experiment are quite incomplete so usually missing hydrogen and quite often you have partial occupancies because of how they refine the structures do you have some sort of orientation orientational flexibility in ligands so then they end up fitting a 50 site here 50 site here so there was a lot of manual effort to actually parse the experimental sifs into something that you could run a dft calculation on and so it's been really nice to see a lot of progress in that area to make and these types of frameworks more tractable i think one nice initiative and came out from from northwestern and coremof which is a data set of computational ready meta-organic frameworks so trying to add hydrogens removing disorder and having a list of structures that you could really plug and play and then of course this year we've just seen and a launching materials project so the maf explorer and it get incredibly exciting to be able to go through so many different maps and and see the range of predicted properties and so i think andrew rosen he did a really nice job with the qmof database which was published last year the year before and and has implemented this in in the materials project so i think this is a really nice feature for people working in the area so that was really when i was starting my research group and i still remember my first phd student he was a few months into his phd and he came to me and said aaron we're in trouble and there's a website that's already done the calculations you asked me to do and so this is uh lee burton and his phd was focused on tin sulfide solar cells so sns related and so one of his first tasks was to sort of perform some thermodynamic calculations and come up with a convex hole for the tin sulfide system and so he found materialsproject.org and found actually there was a convex hole there already and he was a little bit depressed because he's like now what am i going to do for my phd but still there was a lot more to do there was extra phases and there's quite a strong sensitivity to the functional but nonetheless that was my first i think introduction to materials project and for me it was quite eye-opening so it was a real shift in mentality so it sort of standardized a lot of the ground states sort of dft calculations of perfect crystals and raise the bar for the types of research problems that we could start to tackle so instead of reproducing all of these and sort of simple reference systems why not use that data and try to do something more interesting okay so that brings me to the well closer to the present um but what i would say my next step so once i found materials project and that made me think about materials data and thinking about even larger chemical spaces so i ended up going back to some of the quite early research papers i had been reading when i was working at nrel so work in the 1950s and 60s when so people were thinking about electron counting uh related to semiconductors so there was a number of semiconducting families so binary ternaries and quaternary that had been uncharacterized at the time and people like brian pamplin started to think about actually what other semiconductors could exist if we take into account sort of valen valence electron counting rules there should be a whole range of and multi-component semiconductors that should be accessible but at the time it was really just based on electron counting there's no other metric to say sort of would those materials be chemically sensible or would they be stable and so that inspired us to put together i think a relatively simple and package called smacked so semiconductor materials from analogy and chemical theory and so directly inspired for the work of brian pamplin and others at the time but the idea was to and put together a package that could deal with elements and some simple chemical features so that we could explore spaces for sort of millions of combinations and try to filter which ones could be feasible or not and i think the first person to commit some code was keith butler and he was a postdoc in my group at the time and now he's a staff scientist in the scientific machine learning division at sdfc so a uk national lab and then we had many contributions from undergraduate researchers so then this was a really great way to introduce python and introduce some basic package management to various students uh throughout the years and i think dan davis was one of the main contributors and he worked on smackd during his phd and i think he had a visit to berkeley and towards the end of his phd but many other other contributors along the way and anthony he's working on smacked um right now but i think the key approximation at the beginning was really trying to simplify the problem of exploring chemical spaces so saying okay let's ignore structure let's try to explore and build models based purely on composition or element features so can we look at balancing charge balancing electronegativities having some metrics for stable oxidation states and things like that so that was sort of the that was the approach that we followed but towards the end of his phd dan i think he was getting quite ambitious in terms of okay if you want to start to make um strong predictions that could be verified experimentally you really have to integrate structure so then we started to work on metrics for predicting structure quite efficiently and so one of the bottlenecks dan had faced and was the lack of description of structure in trying to train element only models and the issue that you really have is and the inability to describe polymorphs and so here is just the distribution of band gaps and in the materials project for materials with the same composition so it's looking at the spread in bandgap as a property and across different polymorphs and you can see for some materials there's actually quite a large difference so you can have up to a two electron volt difference the same composition in two different structures and so this is going to set a limit to the accuracy of any derived models that don't include structure as a feature and so that made us sort of take a step back and really think about integrating more structure features and more sophisticated or faster ways to predict structure and directly from compositions but i would say since then back in 2019 of course there has been a lot of progress in more complex and elemental features and i'm sure taylor sparks will talk about that next month but in terms of encoding sort of more than just the sort of elemental identity into it into a structure feature but i just wanted to give one example where i think structure has been very important um in in my sort of recent work and that would be the perovskite system and probably many of you whether you like them or not you you've come across the perovskite structure at some stage and but the simple sort of high symmetry prototype is relatively straightforward it's a cubic structure and a primitive unit cell with five five atoms in the basis and the crystal structure was determined back in 1925 with the structure of the mineral form of calcium titanate but the interesting thing about perovskites is not that cubic sort of parent structure it's all of the derived lower symmetry structures that can emerge from that and so it's been shown that there's 23 distinct types of lower symmetry perovskites that can emerge from tilting of those octahedra and you can connect them according to group theory so you have the high symmetry cubic structure on top then you start to remove particular symmetry elements so you can form a tetragonal structure remove another symmetry element from an orthorhombic structure another one from a monophenic structure so you have this family of related structures they're all based on abx-3 they're all based on connected octahedra but it's just the deformations of those octahedra and that vary and but my particular interest has been in the subclass of hybrid halide perovskites so these gained a lot of attention for applications in solar cells and leds and even these days for memristors and other applications and the difference here is that one of the elemental components of the perovskite is replaced by a molecule so it could be something like methylamonium or formamidinium or dna or mda and so different molecules will sit on a lattice site that is occupied by a charged ion in a regular perovskite and the really interesting thing is that these materials if you have metal ammonium leaked chloride for example and they still occupy the regular perovskite structures so these colors represent different compositions that have been reported in various space groups corresponding to tilted and tilted perovskites and polymorphs so a lot of the previous knowledge in terms of the crystallography of oxide perovskites translated very well to the family of hybrid halide materials and one of the first things we noticed when we started to sort of look at these in a little bit more detail is that although the x-ray diffraction tells you one story maybe there's a particular high symmetry and perovskite structure that's present when we look locally for example when you do molecular dynamic simulations you see a lot of disorder so you see vibrations and rotations of the molecular building blocks and you see a lot of motion in the underlying in this case lead iodine framework so a lot of things happening and it made us realize that these structures are highly dynamic and they're not fully described by brag diffraction which is really an average over space and time so if we look at the distribution and of the ions in the system from room temperature and mature dynamic simulations what you see okay the average crystallographic position is indeed um at the center of the distributions but you have very large deviations from the average positions and at the beginning i would say we're a little bit confused about these that are very um elongated ellipsoids around the iodine positions in the structure but of course it makes a lot of sense when you think about tilting of octahedra because this tilting sort of maps out a ellipsoid rather than a sphere so you have these very asymmetric um lobes that are are mapped out but from the iron distributions and so we were sort of shouting to the community a little bit about the some of these features and it managed to get a very nice collaboration with the group of simon billings at columbia university in new york and so he's an expert in inelastic scattering which is a way to probe the local structure and so we've got a very nice validation that indeed although brag diffraction was telling us one thing about the symmetry of these perovskite halide perovskite structures that are sort of quite averaged locally there's a lot more happening and essentially from the inelastic measurements you can in you can um analyze the pair distribution function and what you find is that over different length scales you have the best fit to different crystal structure types so when you look over long length scales for this particular material at this temperature you get a best fit to a cubic perovskite structure but when you look over shorter length scales you get a best fit to a polar um tetragonal and space group so there's a difference between the short range features and the long range behavior and so that was back and so back in 2016 but since then i think experimentally we've been able to probe over shorter and shorter length scales in very nice ways and so i did a collaboration in this case with tiernan doherty and who's a phd student with some strengths in cambridge and they've been using selected area electron diffraction to take some very high performance perovskite solars and films and look at the changes in structure within a grain and between grains and remarkably they can see several things so you can see string gradients within a grain so you see that the effective lattice constant varies within the grain so you have built-in strain in these high performance films but also you have a range of different polymorphs that coexist so you can have tetragonal phases you can have hexagonal polytypes you can have cubic phases that all coexist within these high performance films and so these perovskites are extremely heterogeneous so this is really pushing us to think how we can model such things so the mixture of phases that are present at once um in these films at room temperature and so thinking about larger scale simulations and how we can map out these local distortions in a more efficient way and so my student kazuki morita he spent quite a bit of time thinking of how he could efficiently featurize and distortions in octahedral systems and so going back to some simple group theory and the possible ways that you can deform an octahedron so he realized there's actually only four unique modes so you can take any octahedron and if it's distorted you can map it in essentially into four dimensions so this ends up being a very convenient way to if you're given a set of structures and either separate structures or a structure that's very large and you have a series of distortions over space this is one way that enables you to classify those distortions and so to test the protocol he put together so he initially looked at um ab03 octahedra inside the materials project so he's able to extract 552 octahedra and this is the distribution of distortions so the the index of those four modes for those octahedra and so you can see quite a large spread so you end up getting a peak at zero when you for example if you have a cubic polymorph so you have a perfect octahedron so it could be rock salt it could be a cubic perovskite then you have no distortions but there are a number of structure types and materials that exhibit large distortions over quite a large range so this was quite cool that we could see that a series of distortions were present and digging a little bit further and kazuki found that distortions classified very nicely according to the connectivity between octahedra so whether you have corner sharing networks or edge sharing networks or face sharing networks or some combination of corner sharing and face sharing so the distortions really broke down into these separate sets and so in this case you get the strongest distortions in the combination of these two particular modes when you have a mixture of corner and face sharing and connectivities and so yeah there's some quite nice findings in that particular paper but i don't want to draw on it too long but what kazuki found quite surprisingly and this is really thanks to one of the reviewers pushing us to do this and so he performed a series of molecular dynamic simulations for some halide perovskites and found that a very simple supervised model that just tried to reproduce the energies from the md so a really minimalist model where the only features were the distortions of the octahedra did a very good job so with four dimensions you could get a very good fit to the energies so this this just shows that group theory can be quite useful in terms of informing us in efficient representations of structure so there's a lot of knowledge built in crystallography that we can remap to have more efficient models for training and in machine learning so yeah we're using it for molecular dynamics and but we're also applying it now to look at more complex perovskite polytypes and so jen julie is a postdoc in my group and she's wrote a nice package for generating very complex perovskite sequences so we have mixtures of different connectivities between corner and face sharing and sometimes it's described as a mixture of um cubic and hexagonal poly types and then we can perform various and various analysis to see what type of distortions emerge because there's increasing evidence that these types of intergroups appear both in oxide and in halide perovskite films so because you have a very delicate balance between sometimes these hexagonal and cubic networks that in reality at room temperature you end up getting some mixture of the two and so that's a really fun topic that's sort of attracting our attention okay that brings me to the future so to get back to my title of the grand truth and so i mentioned i i can't remember exactly what the title was but something about uh the grand truth is out there and so when you think about the grand truth of quantum mechanics so i think we're really lucky in a way that compared to many other fields we have the ability to generate our own data so we can make predictions for example with machine learning model of a particular property but we have the ability to calculate we can go back we can solve a set of equations and predict what that value is so i think that active learning and is really going to be a very exciting opportunity in in materials design in the future but nonetheless so grand truth of my quantum mechanics so what we want is a complete description of all interactions in our system so if you think we have a crystal that crystal has atoms sitting at particular sites we want to describe all the interactions between atoms in those in the particular crystal that gives us exact properties of the system so you can start to write down the hamiltonian it may include all the interactions that you need usually the first term is the atom sitting at their positions that generates a periodic potential that periodic potential distributes the electrons that defines the chemical bonds and from that we can determine the energy so that would be the internal energy of the system but depending on the system if you have a small gap or if it's a magnetic system where you have different configurations that can emerge then you have excitations if they're low energy they're going to perturb that static crystal potential you also have vibrations and in the simplest approximations you have harmonic vibrations the atoms are moving in a harmonic potential so then we have a number of almost analytic terms we can incorporate to modify the energies to modify the properties but increasingly for materials research we're driven in a direction where is becoming increasingly important so if you're interested in thermoelectrics it's all about tuning thermal conductivity thermal conductivity is only defined when you have these and harmonic terms so you also have to include some description of an hermann and harmonicity and then you have coupling between vibrations and the electronic states so you have electron phonon coupling to incorporate as well so you think about this mega hamiltonian that starts to describe all of the interactions that are at play to describe the properties that a material has at finite temperatures which is sort of real temperatures at room temperature but often what we do mainly because it's convenient or it makes our job a little bit easier we strike out all of the other terms we say okay let's just keep the static potential let's assume we have a crystal that's static the atoms don't move they are the properties job done that's okay in some cases but of course we're missing many things we're missing free energies so we don't have any temperature or true pressure dependence in the phase diagrams and we're missing thermal expansion which could be positive or could be negative it might be isotropic it might be an isotropic thermal expansion can have a big effect on properties whether it's mechanical instead of changing a bulk modulus whether it's changing a band gap and basically every property is going to depend on how a material expands and the halide perovskites i mentioned before they have some of the largest thermal expansion coefficients of any known solid so you end up having very big changes in structure at room temperature so if you do a static calculation and i say here a thermal because we have no description of temperature not even zero point motion then we have a built-in error and of course to explicit electron phonon interactions can be very important in some cases as well so we have all of these extra terms that we may want to include and of course there are ways to include them so for example if we go to the quasi-harmonic approximation this is sort of a cheap and cheerful way to include the effect of temperature so you have a free energy that depends on the volume of the system essentially what you do is and minimize the volume at for a given temperature you find the volume that minimizes the free energy at a given temperature so for these um rock salt systems you have the lattice constant that changes with temperature and therefore we can we can look at the how a property changes as the structure changes and in this case the bulk modulus can easily change by about 30 percent and when a crystal expands from zero kelvin to room temperature i say cheap and cheerful buzzer harmonic works quite well for many cases but still it's quite approximate now one of the reasons is it's not it can't describe changes in internal degrees of freedom very well so you have to go beyond the quasi-harmonic approximation and in terms of describing these sort of unharmonic contributions to structure to free energies to properties there's been an incredible incredible amount of progress over the past three to five years in new methods but many of them are using things like compressed sensing so instead of explicitly calculating all the terms you can sample the anharmonicity and come up with some effective correction and so at tadano in in scuba he's been doing some really nice work developing the aloe mode code and to include some of those corrections and so he published this preprint and and last autumn so looking at terms that are missing in the quasi-harmonic approximation very interesting to me because before that people we knew there are some things missing but the quasi-harmonic approximation is a little bit peculiar because it's not part of any formal expansion in terms of many body theory so it sort of combines a mixture of different terms but this paper he actually tries to quantify what terms are missing and what's quite curious even systems like sodium chloride and magnesium oxide they're classified as strongly and harmonic so at least me i'd have the intuition that a rock-solid crystal should be quite robust you don't have to worry too much about anaerobicity but actually it's not the case there's a lot of interaction between vibrations that's i think one dimension you can look down and and just heart from heart from twitter so this this particular and tweet got my attention yesterday so maya wrote i don't like people who neglect spin over coupling that's it i've said it and i felt a little bit hurt like she could could have been talking to me because there's many cases where we have to neglect spin-orbit coupling because it's expensive not because we don't know it's important so for example in the halide perfect guides which contain lead we know spin orbit coupling is important but primarily it affects the conduction band where the p band that's formerly empty so we can make assumptions that maybe the dynamics are not so much affected electrodynamics should be okay vibration should be reasonable and we do have some evidence to back that up but generally it can be difficult to justify why we neglect such effects and in fact a few years ago this actually reminded me so with dan davis i had a collaboration with an above sort of looking at some trends in spin orbit coupling so taking sets of materials from the materials project including spin orbit coupling and looking at the impact and here's a series of plots so they're band gap differences so the difference in band gap and calculated with spin-orbit coupling and without spin-over coupling and there's a general assumption that spin-orbit coupling is a constant for a particular element so if you think you have lead you have tin present you're going to result it's going to result in some correction that you need add a shift in the chemical potential add a constant term and that's going to fix your calculations but what we found quite scarily that there's actually quite a large distribution for these heavy elements in the corrections so just looking at lead there's variation between no band gap shift down to a 0.1 1.4 electron volt band gap shift and initially i thought that was a bit strange and so i got done to break it down in terms of oxidation state so you see actually there's many more lead to compounds so most of the distribution isn't led to then i thought okay it must depend either on the coordination environment or on the anion that's present but yet we couldn't see any clear correlation so that's a these plots are trying to show and i think the timing was a little bit early we didn't have any good sort of featurization of structure that we could have plugged in and i think this could really be revisited with some supervised machine learning to try to identify some particular correlations to see what features are driving these distributions could also be that the data was slightly anomalous that's that's possible as well but still it shows the spurious errors that can be built in when we choose a fixed hamiltonian and expect it to be transferable from any materials so this got me thinking but maybe just from another perspective so in terms of materials data and databases so i think from the user of course we want to have absolute data please do the best quality calculations you can give us the best data so that we can use them in our trained models or in fair for sort of our various predictions so you can think of it like a jacob's ladder so we want to get up to heaven and that's from the user perspective so we want the best data possible but i do realize from the curator perspective so if you're maintaining or running the calculations with these databases it might be more similar to a dante's inferno so you have all of these rings of hell that you have to get through because different approximations it can be tricky you end up errors that errors crop up for particular chemistries that you can no longer avoid and and you can have other issues maybe a pseudo potential cannot be used for that particular type of calculation so it's very difficult to have systematic data for all materials so there is a balance there but what i would say so how i'm using materials databases and materials project and pi match n at the moment so just to give you an idea so i'm using it in my undergraduate teaching so my first year undergrads and in materials at imperial they all get to use materials project and in the introduction to crystallography i get them to make their accounts to download structures to play with those structures so that's really really useful uh for my postgraduate teaching um i get you typically get them to use the python api so to actually get an experience of queries of extracting data from databases again very very useful and then for research projects i love the website for informal project planning so during seminars if somebody mentions an interesting compound i'm straight to materials project to check it out some basic properties and then of course for data driven projects having that resource of systematic data is invaluable so i really appreciate all of the effort that goes into maintaining such a database so both in terms of the energies but also the structures that are there but then on the other side of course you do have some perils and i think many people enter this field perhaps not from the computational science background and sometimes they may have the belief that this data is absolute that these are the energies these are the band gaps these are the phase diagrams that is the truth if i build a model that can reproduce it then i've solved everything but i think we know that's not really the case and that there can be many hidden errors but something else that actually caught my interest recently so some of you may have read the book from christoph molnar so he wrote a very nice open source textbook on interpretable machine learning so the various approaches that you can use to open up black box models in different ways and so he posted this recently so i think you've become a little bit cynical about machine learning in general so this is not specifically for materials but that machine learning research has detached itself from solving real problems and created benchmark islands that there's these very large data sets and it seems to be what people want to do is just develop models that can reproduce those data sets with less error and so he highlighted a number of what he called warning signs so the predictive models is its sole measure of progress that the original motivations and assumptions for developing these models are no longer questioned and the actual progress in solving the overarching research questions have become irrelevant or even discouraged i don't think we're there yet for materials i think we're really at the formative stages where people are taking different models seeing how they work trying to develop more accurate and approaches more general more transferable but i think it's quite useful just to pay attention to these warning signs as an editor as a reader and i do come across a number of papers so sometimes i read them and think is that useful for me as a solid state chemistry physicist um but yeah they can be useful in terms of developing the general infrastructure but i think sometimes we have to think about these overarching questions of the big problems that we're trying to solve and i think one of them at least for me is thinking about new chemical spaces so often we're looking for materials with particular properties or to meet a particular figure of merit and i think there are an increasing number of daft predictions in the literature and but sometimes we have a set of very powerful tools um but we just need to have that balance between sort of exploring new chemical spaces and being careful of what we're saying is going to be the next great material and i think alex zunger was really on point in this commentary in nature a few years ago on the burden of proof that we have as materials modelers when we make predictions of a new system that has particular property making sure that it's as realistic as possible and i think at this point in time so we have many indicators of stability so you can think in terms of thermodynamics of locally heat information it's it's usually quite optimistic and you can think globally about convex hulls maybe an open environment interaction with oxygen or water you can think kinetically about the phonons but it's usually quite small displacements you could think about molecular dynamics or maybe even monte carlo methods or come up with a model for synthesizability for machine learning i think we have many indicators right now but personally i haven't seen a quantitative stability figure of merit or machine learning model that i'm really convinced by and i think it's really very much a work in progress and i'm excited to see where the community is going to go over the next few years in terms of being able to predict these realistic candidates and more efficiently and i really enjoyed reading actually one paper from berkeley i think it just appeared this year from christopher bartel and reviewing some of the approaches for stability metrics so thinking about different thermodynamic potentials that we can incorporate and in terms of having more accurate and reliable predictions so apologies for the rant for those sort of a series of things were just on my mind recently and that sort of brings me to the end so thanks if you stay till now that's great and so what i tried to get across was the predictive power of materials modeling i think what i've seen in the last 20 years is incredible in terms of going from these individual calculations solving concham equations to not thinking about tens of thousands of materials but at the same time i think we need to be critical um of the models are being developed and also of the data that we're training those models on if we're going to have robust and meaningful predictions in the future so thanks to my research group and collaborate collaboration network i know roshi yang one of my phd students she's working hard over in berkeley and thanks to everybody else i think materials project and community has been quite forward thinking in terms of reproducible science so i'm not going to dwell much in terms of sharing your codes and data but thank you all for your attention wait thank you so much aaron for the wonderful talk uh we do have some questions in the q a panel if you're able to go ahead and review those uh apologies to anyone whose questions we're not able to answer in the next few minutes but we will have the uh the link open the chairsproject.org seminars where you can repost the questions so aaron are you able to see the question would you like me to moderate or are you able to see them yourself and we can try to answer some of these let me just get my screen going and it should be fine yeah go for it oh i i can see them i said you want me to just go through sure sure yeah any order you'd like so okay so and and above you're an expert on this topic so feel free to chip in as well and so there's one from gabriel mann so can one predict based on atomic number alone which elements have chemically active versus inactive lone pairs i think that's a really good question and it's actually the one i gave to kazuki at the beginning of his phd and he's coming to the end of it right now and back then i think it wasn't possible um in order to produce to get a very sort of good clustering there seems to be this very very delicate balance so even what i'm seeing in the lead halide compounds there's a very large family of lead iodide systems with different counter irons and with some counter rhines you end up getting an inactive lone pair so you get a regular octahedron in other cases then you get this very projected lone pair so more sort of this um deformed either four or five coordinate environment and i think there has to be a chemical explanation exactly why but i haven't seen a good prediction yet in terms of classifying the behavior but i think that's a really really good question so thanks for that gabriel and second question from robert wechsler so there there have been some very impressive advances in using machine learning to fit interdiment potentials or solve the many bodies schrodinger equation so these models however tend to be black box which based on your talk today isn't always desired for an intuition in materials design what's my perspective am i optimistic that simpler theories for materials design will be discovered in the next decade so personally i think machine learning atomic potentials are quite game-changing so i've been involved in quite a number of projects in trying to train new classical potentials so taking some buckingham type potential you have a set of observables you try to find a set of coefficients that fit this particular functional form and it's a nightmare so it's often called a dark art that it's so difficult to train a new interatomic potential and so people spend years trying to even a system like titanium dioxide there's no robust interatomic potential for titanium dioxide that can describe its various polymorphs and its instabilities and but machine learning if you're thinking about sort of these um sort of gaussian approximation type potentials they seem to do an incredibly good job with relatively little data so instead of having a set of clear observables you just sample a set of perturbed structures you train an effective model and it does a really good job so i think especially when you're treating with systems that are polymorphic and if you have for example a crystalline to amorphous phase transition and if you have some complex behavior that you want to describe these seem to do a really really good job so i think for those types of materials it's going to be very useful and will go beyond sort of solving the concham equations because you see they're not interpretable but even dft is not very interpretable either in terms of you're solving this set of partial differential equations that does map between structure and properties but the inter interpretation is usually up to the user so do you interpret the system as covalent or ionic and are you using sort of a cohp type approach there's many different ways and i think machine learning is just like that i think the general trend is more interpretable models so i'm very optimistic for the role of machine learning right now um so a question for baja cahill so can we use synthetic data to fill in the missing pieces so in principle yes i think it really depends on the type of project and i think like others we try to do natural language processing to for example extract data from the literature but you run into problems quite quickly so if you take a material like zinc oxide and you try to do data mining of band gap you'll get a very large range because different groups have different samples that have different impurities different thicknesses different morphologies they fit their optical absorption in different ways so you get a very large range in the values that have been reported and so i think there's a lot of hidden variables in the experimental data that are difficult to extract because they're not in the papers themselves so what with the background defect concentrations what's the dominant orientation of you know of the of the crystals what's the particle size so i think it's difficult but i think if you have a focus project where you're really trying to calculate something that's directly being measured then i think it becomes very useful to combine synthetic and predicted data but if you're trying to do it blindly from the literature i think it's very very difficult i hope that answers your question and next question from gabriel gabriel gabriel is back again and given standard halo perovskites some methylamonium lead bromide what are the smallest and largest terms in the hamiltonian oh and how large is the unharmonic term relative to static potential term so this is actually one of the really big questions right now and there's many high profile papers talking about the high levels of anharmonicity i think generally for these materials if you perform a harmonic and phonon calculation so you calculate a set of frequencies typically the agreement is reasonable with respect to experiment so you get infrared and raman peaks that are reasonable but you also get a number of imaginary modes so imaginary modes that correspond to these tilting of the octahedra as some dynamic instability so that's what the um unharmonic theories allow you to capture so i think in in many cases the room temperature phases are stapled by unharm and harmonic terms so at low temperature you have a very rigid heavily tilted perovskite at room temperature they're heavily dynamic that dynamic behavior is inherently unharmonic so you need to have a double well type potential and but still i think if you're really asking about the order of the terms the unharmonic results in a large contribution to the to the free energy but it's not enough to describe the room temperature phases so you have to go beyond but i think that's a topic that's still under active research and debate right now um also greetings to jacob and gavartan who i think is that schrodinger and these days uh aaron thank you for the thought-provoking talk with regards to the group theoretical analysis you mentioned that these distortions are of yantellor or crystal feed splitting type it's known that these are not reduced they're not reproduced at an lda gj level yet some distortions are represented very well is there common wisdom on when gga can or cannot describe that's a really good question i was a little bit lucky in this case so when you have lead to or tin to it's actually this second order yanteller effect so it's not that you have a partially occupied state that's been split by some on-site by some um some by correlation to give you a filled and empty states it's that you get some coupling between field and empty states that results in a much much more and yeah the physics is it it's a little bit more easy to describe at the lda gga level so this relates to the stereochemical activity or inactivity of the lone pairs so i think if you're dealing with systems like certain transition metals it wouldn't do a good job here but because it's led to and i think in this case it ends up being reasonable because it's this second order yantella effect and so i think it's quite a special case so lee zhang asks what's my view on the questions keep jumping what's my view on machine learning's future to provide more mechanistic scientific details matching those from dft rather than prediction slash engineering so i think that's one of the other streams of research i think somebody mentioned somebody mentioned and some of the deep learning work on trying to have um trying to replace the many bodies schrodinger equation so there's work i know there's a lot of work at deepmind so deepmind in london have hired a number of graduates from um condensed matter physics in imperial i know as one example that have been working on this type of problem so i would not be surprised in the next five years if we see a nature front cover where the schrodinger equation has been replaced by a deep learning model in terms of the accuracy and generality of predictions so it's replacing these pdes by a very large neural network and of course a lot of effort is going to go into the training of that i think the question is once it's trained will that be shared and are we going to be doing fewer and fewer dft calculations and again i think it's going to depend on the property that you're interested in and so maybe if you care about energy or some simple property that's fine i think there's still a lot of effort going to having more sophisticated response functions for example optical properties or magnetic properties where we will still have development using the traditional methods and i see annabath has joined back in so i notice we're a few minutes over time at this point and there's still quite a bit of questions to go so my suggestion is maybe we do a couple more questions and then uh any one whose questions were not answered maybe they can post them on materialsproject.org seminars and then we can try and you know have a community discussion afterwards for some of these other ones so aaron i'll leave it back to you but i realize we're kind of over time now so we might just want to do one or two more okay yeah sort of dinner time in london but thanks for all the questions let me just answer two more and then i will try to answer the rest online if you have them so am i aware of any methods looking into electron excitations or electron forming coupling on the energy materials of finite temperatures and what i've seen is i think separately in the quantum chemistry community people have definitely been working on models for dealing with electronic excitations so going beyond tf dft and trying to train um on sort of higher order sort of post-artery fog methods separately i think we've seen that machine learning models can reproduce phonon and density of states quite well but i haven't seen anything that's predicting for materials electron phonon interactions i think one of the reasons is they're quite expensive to calculate so we don't yet have the data sets that enable training reasonable models so i think that's one of the bottlenecks and it's generating a sufficiently large data set but i suspect some smart people are working on that problem right now but thank you for that anonymous attendee so final question from ebi sam do i expect new unknown features maybe a combination of known features or new ones coming up as key parameters and predicting properties or as approximations to a reasonable range i really hope so because for me that's the exciting thing where if machine learning training all of these models tells us something that we really didn't know and i think for classical potentials there's a lot of understanding of the limitations of two body methods that when you have a pairwise potential it cannot describe these types of phenomena you need to have three body or four body to describe and that sort of tells you something about the nature of the interactions but if we end up identifying some particular features that are very efficient for predicting mechanical properties of vibrational properties and we can understand them i think that's really really cool and instead of just i think the first wave of machine learning for materials was really throwing in every possible feature all of these very random ones like the melting point of the element the range of the melting points the average sometimes you end up getting a model that relies on that feature but it's very difficult as a scientist to really understand is that a meaningful correlation or is it just the fact that you had this random feature that's giving rise to a slightly better model and so i am very very hopeful i think we're going to learn and learn a lot and in terms of the features that end up performing well for particular classes of property and i think that's the last question so thank you all for being so engaged for asking and yeah i see annabelle is back great so thanks so much aaron for the talk and for staying extra and in terms of answering the questions the link to continue the discussion in case you have further questions is in the chat right now so please check that out uh thank you again aaron and we look forward to seeing everybody at the next materials project seminar 